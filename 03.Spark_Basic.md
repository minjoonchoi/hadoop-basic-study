# **Spark**

    아파치 스파크는 대용량 데이터처리용 클러스터 컴퓨팅 프레임워크다.
    스파크는 수행측면에서는 맵리듀스와 유사하지만 자체 분산 런타임 엔진을 가지고 있어서 맵리듀스를 사용하지 않는다.
    YARN기반으로 실행가능하고 하둡 파일포맷과 HDFS 저장소를 지원한다.

    스파크는 잡 사이의 작업 데이터셋을 메모리에 유지할수 있다.
    잡을 실행할때마다 데이터셋을 디스크에서 읽는 맵리듀스 워크플로보다 성능이 좋다.

    스파크에서는 클러스터에 분산 저장된 읽기전용 컬렉션으로 탄력적 분산 데이터셋(RDD : Resilient Distributed Dataset)을 참조한다.
    스파크는 하나 이상의 RDD를 입력받고, 변환작업을 거쳐 목표 RDD 집합으로 변형한다.

## **스파크 애플리케이션**

    스파크는 맵리듀스와 유사하게 잡이라는 개념이 있다.
    맵리듀스 잡은 하나의 맵과 하나의 리듀스로 구성되지만, 스파크 잡은 DAG형태의 스테이지로 구성된다.

    스파크가 실행될 때 스테이지는 다수의 태스크로 분할되고, 각 맵리듀스 태스크는 클러스터에 분산된 RDD 파티션에서 병렬 처리된다.
    스파크 잡은 RDD 및 공유변수를 제공하는 애플리케이션 컨텍스트 내에서 실행된다.
    하나의 애플리케이션은 하나 이상의 잡을 수행할 수 있으며, 다수의 잡이 실행될 때는 이전에 수행된 잡에서 캐싱된 RDD를 재사용할 수 있다.

## **RDD(Resilient Distributed Dataset) : 탄력적 분산 데이터셋**

### **생성**

    RDD를 사용하는 방법은 세 가지가 있다.
    - 객체의 인메모리 컬렉션으로 생성
    - HDFS와 같은 외부저장소 데이터셋 사용
    - 기존 RDD를 변환

    RDD의 병렬 처리 수준은 로컬 컴퓨터의 코어 수나 클러스터의 모든 익스큐터의 총 코어 수에 의해 결정된다.

### **Transformation : 트랜스포메이션 / Action : 액션**

    트랜스포메이션은 기존 RDD에서 새로운 RDD를 생성하고, 액션은 RDD를 계산하여 결과를 만든다.
    액션은 즉시 실행되는 반면에 트랜스포메이션은 지연실행이 적용되어 액션이 실행되는 순간까지 대기하다 액션과 같이 실행된다.

    트랜스포메이션에는 RDD를 반환하며 매핑, 그룹화, 집계, 재분할, 샘플링, 조인 및 집합처리 등이 있다.
    액션에는 통계, 샘플링, 저장 등이 있다.

### **Persistency : 지속성**

    RDD의 cache(), persist() 메소드로 RDD를 캐싱 플래그를 표시하고 액션을 통해 해당 RDD가 로드되면 그 때 메모리에 캐싱한다.
    스파크는 클러스터의 각 머신에 있는 메모리에 RDD 파티션을 분산하여 캐싱한다.

    cache()는 익스큐터의 메모리에 각 RDD 파티션을 보존하지만, 익스큐터의 메모리가 충분하지 않다면 필요에 따라 계산을 다시 수행한다.
    persist()는 'StorageLevel'을 인자로 지속성 레벨을 설정할 수 있다.
    - MEMORY_ONLY : 기본 값으로 메모리에 객체를 저장한다.
    - MEMORY_ONLY_SER : 파티션을 바이트 배열로 직렬화하여 메모리에 저장하고, 객체가 아니기 때문에 GC 부담을 줄인다.
    - MEMORY_AND_DISK : 객체를 메모리에 먼저 저장하고 충분하지 않으면 디스크에 스필하여 저장한다.
    - MEMORY_AND_DISK_SER : 직렬화된 바이트 배열을 메모리에 저장하며, 메모리가 충분하지 않으면 디스크에 저장한다.

### **Serialization : 직렬화**

    스파크는 RDD 파티션을 네트워크 전송하거나 캐싱할 때 기본적으로 자바 직렬화 매커니즘을 사용한다.
    하지만, 자바 직렬화보다 '크라이오(Kryo)' 직렬화를 사용하는 것이 효율적이다.
    크라이오 직렬화를 사용할 때 직렬화를 위한 사용자의 데이터 레코드 클래스를 등록하는 것이 더 효율적이다.

```java
class CustomKryoRegistor extends KryoRegister {
    override def registerClasses(kryo: Kryo){
        kryo.register(classOf[RecordClass])
    }
}
```
```java
conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
conf.set("spark.kryo.registrator", "CustomKryoRegistor")
```

## **공유변수**

### **Broadcast : 브로드캐스트 변수**

    브로드캐스트 변수는 직렬화 되어 각 익스큐터에 전송되며 태스크가 필요에 따라 참조할 수 있도록 캐싱된다.
    맵리듀스의 분산캐시와 유사하지만 스파크는 메모리가 충분하면 메모리에 저장하고 부족하면 나머지를 디스크에 저장하는 차이가 있다.

    브로드캐스트 변수는 value() 메소드로 값을 호출해야하는 것을 주의해야하고, 값을 변경하거나 드라이버로 역전파하는 방법은 없다.

### **Accumulator : 어큐뮬레이터 변수**

    맵리듀스의 카운터와 유사하게 태스크에서 값을 증가만 시킬 수 있는 변수다.
    잡이 완료되면 드라이버에서 값을 조회할수 있다.
    어큐뮬레이터 변수도 value() 메소드로 값을 호출해야한다.

## **스파크 잡 분석**

    스파크는 드라이버(Driver)와 익스큐터(Executor)로 나뉜다.
    드라이버는 애플리케이션을 관리하고 태스크 스케줄링을 한다.
    익스큐터는 애플리케이션을 실행하고 태스크를 실행한다.
    
    드라이버는 일반적으로 클러스터 외부의 클라이언트에서 실행된다.
    익스큐터는 클러스터에 포함된 머신에서 실행된다.

    잡은 스테이지로 구분되며 스테이지에서는 셔플 맵 태스크와 결과 태스크가 실행된다.
    셔플 맵 태스크는 맵리듀스 셔플의 맵과 비슷하고, RDD 파티션당 하나의 계산을 실행하고 새로운 파티션 집합네 저장한다.
    결과 태스크는 결과를 사용자 프로그램에 돌려주는 마지막 스테이지에서 실행된다.
    각 태스크는 드라이버에서 DAG스케줄러와 태스크스케줄러를 거쳐 데이터지역성를 고려해 익스큐터에 할당된다.

## **익스큐터와 클러스터 매니저**

    클러스터 매니저는 익스큐터의 라이프사이클을 관리하고 다음과 같이 분류된다.
    - 로컬 : 로컬모드는 드라이버와 동일한 JVM에서 실행되는 단일 익스큐터가 있다.
    - 독립 : 단일 스파크 마스터와 하나 이상의 워커로 실행되는 분산 방식이다.
    - 메소스(Mesos) : 아파치 메소스는 클러스터 자원을 조직의 정책에 따라 세밀하게 관리할 수 있는 기능을 제공한다.
    - YARN : 하둡에서 사용하는 리소스 매니저로 각 익스큐터의 YARN 컨테이너에서 스파크 애플리케이션이 실행된다.

### **YARN에서 스파크**

    YARN에서 스파크를 실행할 때는 클라이언트 모드와 클러스터 모드가 있다.
    클라이언트 모드는 클라이언트에서 드라이버가 실행된다.
    클러스터 모드는 클러스터의 YARN 애플리케이션 마스터에서 드라이버가 실행된다.

    두 모드의 차이는 드라이버 프로그램이 실행되는 위치에 차이가 있고 잡의 실행순서는 아래와 같다.

    클라이언트 모드는 클라이언트에서 스파크 애플리케이션이 실행되면 스파크 컨택스트가 생성된다.
    스파크 컨택스트는 YARN 애플리케이션을 리소스매니저에 제출한다.
    리소스매니저는 노드매니저를 할당하여 익스큐터와 애플리케이션 마스터를 시작시킨다.
    애플리케이션 마스터는 필요시 추가 자원을 요청한다.
    자원할당이 완료되면 각 익스큐터에서 계산이 시작된다.

    클러스터 모드는 클라이언트에서 리소스메니저에 YARN 애플리케이션을 직접 제출한다.
    리소스매니저는 노드매니저를 할당해 익스큐터와 애플리케이션 마스터를 시작시킨다.
    애플리케이션 마스터는 드라이버 프로그램을 구동하고 필요시 추가 자원을 요청한다.
    자원할당이 완료되면 각 익스큐터에서 계산이 시작된다.
